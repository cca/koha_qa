# a lot our 041 language codes are all stuffed into one $a subfield
# instead of a separate $a for each language code
# 041 1_ $aengjpn -> 041 1_ $aeng$ajpn
from pathlib import Path
from typing import Set

import click
from pymarc import Record, Subfield, MARCReader, MARCWriter, Field

# List of ISO 639.2 language codes
# https://www.loc.gov/standards/iso639-2/php/code_list.php
codes: list[str] = [
    "aar",
    "abk",
    "ace",
    "ach",
    "ada",
    "ady",
    "afa",
    "afh",
    "afr",
    "ain",
    "aka",
    "akk",
    "alb",
    "ale",
    "alg",
    "alt",
    "amh",
    "ang",
    "anp",
    "apa",
    "ara",
    "arc",
    "arg",
    "arm",
    "arn",
    "arp",
    "art",
    "arw",
    "asm",
    "ast",
    "ath",
    "aus",
    "ava",
    "ave",
    "awa",
    "aym",
    "aze",
    "bad",
    "bai",
    "bak",
    "bal",
    "bam",
    "ban",
    "baq",
    "bas",
    "bat",
    "bej",
    "bel",
    "bem",
    "ben",
    "ber",
    "bho",
    "bih",
    "bik",
    "bin",
    "bis",
    "bla",
    "bnt",
    "tib",
    "bos",
    "bra",
    "bre",
    "btk",
    "bua",
    "bug",
    "bul",
    "bur",
    "byn",
    "cad",
    "cai",
    "car",
    "cat",
    "cau",
    "ceb",
    "cel",
    "cze",
    "cha",
    "chb",
    "che",
    "chg",
    "chi",
    "chk",
    "chm",
    "chn",
    "cho",
    "chp",
    "chr",
    "chu",
    "chv",
    "chy",
    "cmc",
    "cnr",
    "cop",
    "cor",
    "cos",
    "cpe",
    "cpf",
    "cpp",
    "cre",
    "crh",
    "crp",
    "csb",
    "cus",
    "wel",
    "cze",
    "dak",
    "dan",
    "dar",
    "day",
    "del",
    "den",
    "ger",
    "dgr",
    "din",
    "div",
    "doi",
    "dra",
    "dsb",
    "dua",
    "dum",
    "dut",
    "dyu",
    "dzo",
    "efi",
    "egy",
    "eka",
    "gre",
    "elx",
    "eng",
    "enm",
    "epo",
    "est",
    "baq",
    "ewe",
    "ewo",
    "fan",
    "fao",
    "per",
    "fat",
    "fij",
    "fil",
    "fin",
    "fiu",
    "fon",
    "fre",
    "fre",
    "frm",
    "fro",
    "frr",
    "frs",
    "fry",
    "ful",
    "fur",
    "gaa",
    "gay",
    "gba",
    "gem",
    "geo",
    "ger",
    "gez",
    "gil",
    "gla",
    "gle",
    "glg",
    "glv",
    "gmh",
    "goh",
    "gon",
    "gor",
    "got",
    "grb",
    "grc",
    "gre",
    "grn",
    "gsw",
    "guj",
    "gwi",
    "hai",
    "hat",
    "hau",
    "haw",
    "heb",
    "her",
    "hil",
    "him",
    "hin",
    "hit",
    "hmn",
    "hmo",
    "hrv",
    "hsb",
    "hun",
    "hup",
    "arm",
    "iba",
    "ibo",
    "ice",
    "ido",
    "iii",
    "ijo",
    "iku",
    "ile",
    "ilo",
    "ina",
    "inc",
    "ind",
    "ine",
    "inh",
    "ipk",
    "ira",
    "iro",
    "ice",
    "ita",
    "jav",
    "jbo",
    "jpn",
    "jpr",
    "jrb",
    "kaa",
    "kab",
    "kac",
    "kal",
    "kam",
    "kan",
    "kar",
    "kas",
    "geo",
    "kau",
    "kaw",
    "kaz",
    "kbd",
    "kha",
    "khi",
    "khm",
    "kho",
    "kik",
    "kin",
    "kir",
    "kmb",
    "kok",
    "kom",
    "kon",
    "kor",
    "kos",
    "kpe",
    "krc",
    "krl",
    "kro",
    "kru",
    "kua",
    "kum",
    "kur",
    "kut",
    "lad",
    "lah",
    "lam",
    "lao",
    "lat",
    "lav",
    "lez",
    "lim",
    "lin",
    "lit",
    "lol",
    "loz",
    "ltz",
    "lua",
    "lub",
    "lug",
    "lui",
    "lun",
    "luo",
    "lus",
    "mac",
    "mad",
    "mag",
    "mah",
    "mai",
    "mak",
    "mal",
    "man",
    "mao",
    "map",
    "mar",
    "mas",
    "may",
    "mdf",
    "mdr",
    "men",
    "mga",
    "mic",
    "min",
    "mis",
    "mac",
    "mkh",
    "mlg",
    "mlt",
    "mnc",
    "mni",
    "mno",
    "moh",
    "mon",
    "mos",
    "mao",
    "may",
    "mul",
    "mun",
    "mus",
    "mwl",
    "mwr",
    "bur",
    "myn",
    "myv",
    "nah",
    "nai",
    "nap",
    "nau",
    "nav",
    "nbl",
    "nde",
    "ndo",
    "nds",
    "nep",
    "new",
    "nia",
    "nic",
    "niu",
    "dut",
    "nno",
    "nob",
    "nog",
    "non",
    "nor",
    "nqo",
    "nso",
    "nub",
    "nwc",
    "nya",
    "nym",
    "nyn",
    "nyo",
    "nzi",
    "oci",
    "oji",
    "ori",
    "orm",
    "osa",
    "oss",
    "ota",
    "oto",
    "paa",
    "pag",
    "pal",
    "pam",
    "pan",
    "pap",
    "pau",
    "peo",
    "per",
    "phi",
    "phn",
    "pli",
    "pol",
    "pon",
    "por",
    "pra",
    "pro",
    "pus",
    "qaa",
    "que",
    "raj",
    "rap",
    "rar",
    "roa",
    "roh",
    "rom",
    "rum",
    "rum",
    "run",
    "rup",
    "rus",
    "sad",
    "sag",
    "sah",
    "sai",
    "sal",
    "sam",
    "san",
    "sas",
    "sat",
    "scn",
    "sco",
    "sel",
    "sem",
    "sga",
    "sgn",
    "shn",
    "sid",
    "sin",
    "sio",
    "sit",
    "sla",
    "slo",
    "slo",
    "slv",
    "sma",
    "sme",
    "smi",
    "smj",
    "smn",
    "smo",
    "sms",
    "sna",
    "snd",
    "snk",
    "sog",
    "som",
    "son",
    "sot",
    "spa",
    "alb",
    "srd",
    "srn",
    "srp",
    "srr",
    "ssa",
    "ssw",
    "suk",
    "sun",
    "sus",
    "sux",
    "swa",
    "swe",
    "syc",
    "syr",
    "tah",
    "tai",
    "tam",
    "tat",
    "tel",
    "tem",
    "ter",
    "tet",
    "tgk",
    "tgl",
    "tha",
    "tib",
    "tig",
    "tir",
    "tiv",
    "tkl",
    "tlh",
    "tli",
    "tmh",
    "tog",
    "ton",
    "tpi",
    "tsi",
    "tsn",
    "tso",
    "tuk",
    "tum",
    "tup",
    "tur",
    "tut",
    "tvl",
    "twi",
    "tyv",
    "udm",
    "uga",
    "uig",
    "ukr",
    "umb",
    "und",
    "urd",
    "uzb",
    "vai",
    "ven",
    "vie",
    "vol",
    "vot",
    "wak",
    "wal",
    "war",
    "was",
    "wel",
    "wen",
    "wln",
    "wol",
    "xal",
    "xho",
    "yao",
    "yap",
    "yid",
    "yor",
    "ypk",
    "zap",
    "zbl",
    "zen",
    "zgh",
    "zha",
    "chi",
    "znd",
    "zul",
    "zun",
    "zxx",
    "zza",
]


def split_lang_codes(record: Record, debug: bool) -> Record:
    """Split multiple language codes in 041 $a into separate subfields"""
    invalid_codes: Set[str] = set()
    invalid_3letter_codes: Set[str] = set()
    valid_codes: Set[str] = set()
    for field in record.get_fields("041"):
        # only process fields that use the MARC language codes
        if field.indicator2 == " ":
            if debug:
                click.echo(f"Processing field {field}")

            # sort subfields into categories
            for code in field.get_subfields("a"):
                if len(code) != 3:
                    invalid_codes.add(code)
                elif len(code) == 3 and code not in codes:
                    click.echo(
                        f"Warning: unrecognized language code {code} in field {field} in record {record.title}",
                        err=True,
                    )
                    invalid_3letter_codes.add(code)
                else:
                    valid_codes.add(code)

            if invalid_codes:
                if debug:
                    click.echo(f"Invalid subfield values: {invalid_codes}")

                for code in invalid_codes:
                    if len(code) % 3 == 0:
                        for i in range(0, len(code), 3):
                            # this step also fixes uppercase codes
                            split_code: str = code[i : i + 3].lower()
                            if split_code in codes:
                                valid_codes.add(split_code)
                            # we have a number of records using the wrong code for Japanese
                            elif split_code == "jap":
                                valid_codes.add("jpn")
                            elif split_code == "esk":
                                # NOTE: assumes language is Inuktitut & not another Inuit language
                                # like IÃ±upiaq (ipk). This is true for our collection though & Inuktitut
                                # is the most common. Note that `iku` also covers Inuinnaqtun.
                                # https://en.wikipedia.org/wiki/Eskaleut_languages#Internal_classification
                                valid_codes.add("iku")
                            else:
                                click.echo(
                                    f"Warning: unrecognized language code {split_code} after splitting {field} in record {record.title}. This code will be removed from the record.",
                                    err=True,
                                )
                new_field: Field = Field(
                    tag="041",
                    indicators=field.indicators,
                    subfields=[Subfield(code="a", value=code) for code in valid_codes],
                )

                if debug:
                    click.echo(f"New field: {new_field}")

                record.remove_field(field)
                record.add_ordered_field(new_field)

    return record


@click.command()
@click.help_option("--help", "-h")
@click.argument(
    "input",
    metavar="input.mrc",
    type=click.Path(exists=True, dir_okay=False, readable=True),
)
@click.argument(
    "output",
    metavar="output.mrc",
    type=click.Path(dir_okay=False, writable=True),
    required=False,
)
@click.option("--debug", "-d", is_flag=True, help="Print changes, do not write to file")
def main(input: Path, output: Path, debug: bool) -> None:
    """Takes MARC 041 language subfields where multiple language codes are in a single $a subfield and splits them into separate subfields. Example: 041 1_ $a engjpn -> 041 1_ $a eng $a jpn (spaces added for readability)"""
    with open(input, "rb") as input_fh:
        if output:
            writer = MARCWriter(open(output, "wb"))
        reader = MARCReader(input_fh)
        for record in reader:
            if record:
                new_record: Record = split_lang_codes(record, debug)
                if not debug and output:
                    writer.write(new_record)
        if output:
            writer.close()


if __name__ == "__main__":
    main()
